{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen seleccionada: C:/Users/Matias/Desktop/Tesis/Dataset_Neoplasias\\SCC\\oral_SCC_OSCC_400x_233_1_98ff8902-60e5-439d-b60f-dc3416a14fa3_1.JPEG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Matias\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\cuda\\memory.py:444: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.memory_cached()\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, confusion_matrix\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "# from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
    "import best_modelo_general as bmg\n",
    "import best_modelo_general_colon as bmgc\n",
    "import best_modelo_general_lung as bmgl\n",
    "import best_modelo_general_gastrointestinal as bmgg\n",
    "import best_modelo_general_oral as bmgo\n",
    "\n",
    "\n",
    "\n",
    "# Aca va el optmizador de profundidad\n",
    "import opt_deep_analysis as opt_deep\n",
    "\n",
    "sys.path.append(\"C:/Users/Matias/Desktop/Tesis/Tesis-Codes/utils\")\n",
    "import creacion_df_torch as qol\n",
    "\n",
    "\n",
    "\n",
    "dataset_dir = r\"C:/Users/Matias/Desktop/Tesis/Dataset_Neoplasias\"\n",
    "\n",
    "# Preparar datos\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "df = qol.crear_dataframe_binario(dataset_dir, filtro_cancer='all')\n",
    "train_loader, val_loader, test_loader = qol.prepare_data_loaders(df, batch_size=80, m_type='bin')\n",
    "\n",
    "#Preparamos\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Ruta al directorio del dataset\n",
    "dataset_dir = r\"C:/Users/Matias/Desktop/Tesis/Dataset_Neoplasias\"\n",
    "\n",
    "\n",
    "# Preparar los DataLoaders (usando el DataFrame binario como ejemplo)\n",
    "# Guardar el DataFrame de prueba\n",
    "_, test_val_df = train_test_split(df, test_size=0.3, random_state=46, stratify=df['etiqueta'])\n",
    "_, test_df = train_test_split(test_val_df, test_size=0.33, random_state=46, stratify=test_val_df['etiqueta'])\n",
    "\n",
    "\n",
    "\n",
    "# Seleccionar una imagen del conjunto de prueba\n",
    "imagen_prueba = test_df.sample(n=1).iloc[0]\n",
    "ruta_imagen_prueba = imagen_prueba['ruta']\n",
    "\n",
    "print(f\"Imagen seleccionada: {ruta_imagen_prueba}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def crear_dataframe(dataset_dir):\n",
    "    subcarpetas = ['benigno', 'maligno']\n",
    "    data = {'ruta': [], 'etiqueta': [], 'tipo': []}\n",
    "    \n",
    "    for subcarpeta in subcarpetas:\n",
    "        dir_path = os.path.join(dataset_dir, subcarpeta)\n",
    "        for filename in os.listdir(dir_path):\n",
    "            parts = filename.split('_')\n",
    "            \n",
    "            if len(parts) > 2 and (parts[0] == 'oral'):\n",
    "                tipo_cancer = parts[0]\n",
    "                etiqueta = parts[1]\n",
    "            elif len(parts) == 3:\n",
    "                tipo_cancer, etiqueta, _ = parts\n",
    "            else:\n",
    "                print(f\"Archivo {filename} ignorado por tener un formato incorrecto.\")\n",
    "                continue\n",
    "                \n",
    "            ruta_completa = os.path.join(dir_path, filename)\n",
    "            data['ruta'].append(ruta_completa)\n",
    "            data['etiqueta'].append(etiqueta)\n",
    "            data['tipo'].append(tipo_cancer)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def dividir_dataframe(df, test_size=0.2, val_size=0.25, random_state=42):\n",
    "    df_train, df_temp = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "    df_val, df_test = train_test_split(df_temp, test_size=val_size, random_state=random_state)\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "def crear_generadores_por_tipo(df_train, df_val, target_size=(256, 256), batch_size=20):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=df_train,\n",
    "        x_col='ruta',\n",
    "        y_col='etiqueta',\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    validation_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=df_val,\n",
    "        x_col='ruta',\n",
    "        y_col='etiqueta',\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, validation_generator\n",
    "\n",
    "def crear_generador_test(df_test, target_size=(256, 256), batch_size=20):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    test_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=df_test,\n",
    "        x_col='ruta',\n",
    "        y_col='etiqueta',\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return test_generator\n",
    "\n",
    "# Función para calcular métricas\n",
    "def calcular_metricas(model, generator):\n",
    "    y_true = generator.classes\n",
    "    y_pred_prob = model.predict(generator)\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return accuracy, recall, precision, f1\n",
    "\n",
    "def get_pretrained_model(model_name, input_shape=(256, 256, 3), num_classes=1):\n",
    "    if model_name == 'resnet':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif model_name == 'vgg':\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif model_name == 'densenet':\n",
    "        base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model name\")\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    predictions = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    return model\n",
    "\n",
    "def entrenar_modelo(model, train_gen, val_gen, tipo_cancer, model_name, epochs=10):\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_gen,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_gen)\n",
    "\n",
    "    model_dir = f'C:/Users/Matias/OneDrive/Escritorio/Tesis/Tesis-Models/Model_Analsis_final/{tipo_cancer}_pretrained_models'\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model.save(os.path.join(model_dir, f'{tipo_cancer}_modelo_{model_name}.h5'))\n",
    "    \n",
    "    with open(os.path.join(model_dir, f'{tipo_cancer}_historial_{model_name}.pickle'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def ocultar_seccion(imagen, top_left, tamano, valor_ocultacion=0.5):\n",
    "    imagen_modificada = np.copy(imagen)\n",
    "    x, y = top_left\n",
    "    ancho, alto = tamano\n",
    "    imagen_modificada[y:y+alto, x:x+ancho, :] = valor_ocultacion\n",
    "    return imagen_modificada\n",
    "\n",
    "def generar_mostrar_mapa_calor(ruta_imagen, modelo, tamano_parche=32, paso=16):\n",
    "    partes_ruta = ruta_imagen.split('/')  \n",
    "    clase_real = partes_ruta[-2]\n",
    "\n",
    "    imagen = load_img(ruta_imagen, target_size=(256, 256))\n",
    "    imagen_array = img_to_array(imagen) / 255.0\n",
    "    mapa_calor = np.zeros((imagen_array.shape[0], imagen_array.shape[1]))\n",
    "\n",
    "    prediccion_original = modelo.predict(np.expand_dims(imagen_array, axis=0), verbose=0)[0][0]\n",
    "    clase_predicha = 'maligno' if prediccion_original > 0.5 else 'benigno'\n",
    "\n",
    "    for y in range(0, imagen_array.shape[0] - tamano_parche, paso):\n",
    "        for x in range(0, imagen_array.shape[1] - tamano_parche, paso):\n",
    "            imagen_modificada = ocultar_seccion(imagen_array, (x, y), (tamano_parche, tamano_parche))\n",
    "            prediccion_modificada = modelo.predict(np.expand_dims(imagen_modificada, axis=0), verbose=0)[0][0]\n",
    "            cambio_prediccion = np.abs(prediccion_original - prediccion_modificada)\n",
    "            mapa_calor[y:y+tamano_parche, x:x+tamano_parche] += cambio_prediccion\n",
    "\n",
    "    mapa_calor = mapa_calor / np.max(mapa_calor)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    \n",
    "    axs[0].imshow(imagen)\n",
    "    axs[0].set_title(f'Original - Real: {clase_real}, Predicha: {clase_predicha}')\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    axs[1].imshow(imagen)\n",
    "    axs[1].imshow(mapa_calor, cmap='jet', alpha=0.5)\n",
    "    axs[1].set_title(f'Mapa de Calor {modelo}')\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rutas de las imágenes seleccionadas:\n",
      "C:/Users/Matias/Desktop/Tesis/Dataset_Neoplasias\\ACA\\colon_ACA_colonca1239.jpeg\n",
      "C:/Users/Matias/Desktop/Tesis/Dataset_Neoplasias\\benigno\\oral_benigno_Normal_400x_119_1_e4c3ef68-b960-4cbc-9ebe-bd571216a4b1_1.JPEG\n",
      "C:/Users/Matias/Desktop/Tesis/Dataset_Neoplasias\\ACA\\colon_ACA_colonca1187.jpeg\n",
      "C:/Users/Matias/Desktop/Tesis/Dataset_Neoplasias\\SCC\\oral_SCC_OSCC_100x_364_1_85ce1c2b-3264-49b8-95ae-8f8e241191c4_1.JPEG\n",
      "C:/Users/Matias/Desktop/Tesis/Dataset_Neoplasias\\benigno\\oral_benigno_Normal_400x_146_1_23f36fd0-67ff-4a1c-ae55-43bc790bf318_1.JPEG\n",
      "C:/Users/Matias/Desktop/Tesis/Dataset_Neoplasias\\ACA\\lung_ACA_lungaca2316.jpeg\n",
      "C:/Users/Matias/Desktop/Tesis/Dataset_Neoplasias\\SCC\\oral_SCC_OSCC_100x_240_1_09ba41ea-3c15-40a6-b99f-170a31c12558_1.JPEG\n",
      "C:/Users/Matias/Desktop/Tesis/Dataset_Neoplasias\\ACA\\gastrointestinal_ACA_STU-FGWWGSTWQIHQ.png\n",
      "C:/Users/Matias/Desktop/Tesis/Dataset_Neoplasias\\SCC\\oral_SCC_OSCC_400x_315_1_e1cfcb97-1197-4d0c-a6e7-3dd9ab9a8f06_1.JPEG\n",
      "C:/Users/Matias/Desktop/Tesis/Dataset_Neoplasias\\ACA\\lung_ACA_lungaca829.jpeg\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar 10 imágenes del conjunto de prueba\n",
    "imagenes_prueba = test_df.sample(n=10, random_state=46)\n",
    "rutas_imagenes_prueba = imagenes_prueba['ruta'].tolist()\n",
    "\n",
    "# Lista para almacenar las imágenes cargadas\n",
    "imagenes_cargadas = []\n",
    "\n",
    "# Cargar las imágenes seleccionadas\n",
    "for ruta in rutas_imagenes_prueba:\n",
    "    img = Image.open(ruta)\n",
    "    imagenes_cargadas.append(img)\n",
    "\n",
    "# Mostrar las rutas de las imágenes seleccionadas\n",
    "print(\"Rutas de las imágenes seleccionadas:\")\n",
    "for ruta in rutas_imagenes_prueba:\n",
    "    print(ruta)\n",
    "\n",
    "# Si quieres visualizar alguna imagen de las seleccionadas\n",
    "imagenes_cargadas[0].show()  # Muestra la primera imagen, por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.3789\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Definir el directorio donde se guardarán los gráficos y las imágenes Grad-CAM\n",
    "output_dir = r\"C:/Users/Matias/Desktop/Tesis/Tesis-Codes/Best_Optuna_Models/loss_grad_images\"\n",
    "\n",
    "# Crear el directorio si no existe\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Definir el modelo\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_filters1, num_filters2, num_filters3, kernel_size, dropout_rate, num_classes, input_size=256):\n",
    "        super(Net, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, num_filters1, kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(num_filters1, num_filters2, kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(num_filters2, num_filters3, kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        output_size = input_size\n",
    "        for _ in range(3):  # Dado que tenemos tres bloques de Conv + MaxPool\n",
    "            output_size = (output_size - kernel_size + 2 * 1) / 1 + 1  # Aplicamos la fórmula del tamaño de salida\n",
    "            output_size = output_size // 2  # MaxPooling divide el tamaño por 2\n",
    "\n",
    "        output_features = int(output_size * output_size * num_filters3)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(output_features, num_classes),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Entrenar el modelo y aplicar Grad-CAM a 10 imágenes\n",
    "def train_and_apply_gradcam(device, train_loader, val_loader, test_loader, selected_images):\n",
    "    num_classes = 2  # Actualizar según el número de clases\n",
    "    model = Net(num_filters1=32, num_filters2=512, num_filters3=256, kernel_size=4, dropout_rate=0.4711483566097797, num_classes=num_classes).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0004701163660665632)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Entrenamiento (simplificado a 2 épocas para la demostración)\n",
    "    for epoch in range(10):\n",
    "        running_loss = 0.0\n",
    "        steps = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            steps += 1\n",
    "\n",
    "        train_losses.append(running_loss / steps)\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {running_loss/steps:.4f}')\n",
    "\n",
    "        # Validación (para simplificación se usa la misma lógica de loss)\n",
    "        val_loss = 0.0\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "    # Graficar y guardar las pérdidas\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, 'loss_plot.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Aplicar Grad-CAM a las 10 imágenes seleccionadas\n",
    "    target_layer = model.features[-1]\n",
    "    gradcam = qol.GradCAM(model, target_layer)\n",
    "\n",
    "    for idx, img_path in enumerate(selected_images):\n",
    "        # Cargar la imagen original\n",
    "        img = qol.load_image(img_path).to(device)\n",
    "        original_img = to_pil_image(img.cpu())\n",
    "\n",
    "        # Generar el Grad-CAM\n",
    "        gradcam_mask = gradcam.generate(img.unsqueeze(0))\n",
    "        heatmap = qol.show_cam_on_image(np.array(original_img), gradcam_mask)\n",
    "\n",
    "        # Guardar la imagen original y la Grad-CAM\n",
    "        original_img.save(os.path.join(output_dir, f'custom_model_original_image_{idx}.png'))\n",
    "        Image.fromarray(heatmap).save(os.path.join(output_dir, f'custom_model_gradcam_image_{idx}.png'))\n",
    "\n",
    "        print(f\"Imagen {idx+1}: {img_path} procesada y guardada.\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Funciones auxiliares como Grad-CAM y carga de imagen ya definidas en el código original\n",
    "# Asumiendo que ya tienes el DataFrame con las rutas de las imágenes seleccionadas:\n",
    "rutas_imagenes_prueba = test_df.sample(n=10, random_state=46)['ruta'].tolist()\n",
    "\n",
    "# Ejecutar el entrenamiento y aplicar Grad-CAM a las imágenes seleccionadas\n",
    "train_and_apply_gradcam(device, train_loader, val_loader, test_loader, rutas_imagenes_prueba)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preentrenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Definir el directorio donde se guardarán los gráficos y las imágenes Grad-CAM\n",
    "output_dir = r\"C:/Users/Matias/Desktop/Tesis/Tesis-Codes/Best_Optuna_Models/loss_grad_images\"\n",
    "\n",
    "# Crear el directorio si no existe\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Función para entrenar y generar gráficos de loss\n",
    "def entrenar_y_mostrar_loss(model, train_gen, val_gen, tipo_cancer, model_name, epochs=10):\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_gen,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_gen)\n",
    "\n",
    "    # Graficar las pérdidas y guardarlas en la carpeta correspondiente\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Training and Validation Loss - {model_name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, f'{model_name}_loss_plot.png'))\n",
    "    plt.close()\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# Función para generar y guardar el mapa de calor (Grad-CAM)\n",
    "def generar_guardar_mapa_calor(ruta_imagen, modelo, model_name, tamano_parche=32, paso=16):\n",
    "    partes_ruta = ruta_imagen.split('/')\n",
    "    clase_real = partes_ruta[-2]\n",
    "\n",
    "    imagen = load_img(ruta_imagen, target_size=(256, 256))\n",
    "    imagen_array = img_to_array(imagen) / 255.0\n",
    "    mapa_calor = np.zeros((imagen_array.shape[0], imagen_array.shape[1]))\n",
    "\n",
    "    prediccion_original = modelo.predict(np.expand_dims(imagen_array, axis=0), verbose=0)[0][0]\n",
    "    clase_predicha = 'maligno' if prediccion_original > 0.5 else 'benigno'\n",
    "\n",
    "    for y in range(0, imagen_array.shape[0] - tamano_parche, paso):\n",
    "        for x in range(0, imagen_array.shape[1] - tamano_parche, paso):\n",
    "            imagen_modificada = ocultar_seccion(imagen_array, (x, y), (tamano_parche, tamano_parche))\n",
    "            prediccion_modificada = modelo.predict(np.expand_dims(imagen_modificada, axis=0), verbose=0)[0][0]\n",
    "            cambio_prediccion = np.abs(prediccion_original - prediccion_modificada)\n",
    "            mapa_calor[y:y+tamano_parche, x:x+tamano_parche] += cambio_prediccion\n",
    "\n",
    "    mapa_calor = mapa_calor / np.max(mapa_calor)\n",
    "\n",
    "    # Guardar la imagen original y el mapa de calor\n",
    "    plt.imsave(os.path.join(output_dir, f'{model_name}_original_{os.path.basename(ruta_imagen)}'), imagen)\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(imagen)\n",
    "    plt.imshow(mapa_calor, cmap='jet', alpha=0.5)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(output_dir, f'{model_name}_gradcam_{os.path.basename(ruta_imagen)}'))\n",
    "    plt.close()\n",
    "\n",
    "# Entrenar y aplicar Grad-CAM para cada modelo preentrenado\n",
    "# Crear generadores\n",
    "df_train, df_val, df_test = dividir_dataframe(df)\n",
    "train_generator, validation_generator, test_generator = crear_generadores_por_tipo(df_train, df_val, df_test)\n",
    "resnet_model = get_pretrained_model('resnet')\n",
    "vgg_model = get_pretrained_model('vgg')\n",
    "densenet_model = get_pretrained_model('densenet')\n",
    "\n",
    "# Entrenar y mostrar la loss de cada modelo\n",
    "resnet_model, resnet_history = entrenar_y_mostrar_loss(resnet_model, train_generator, validation_generator, 'oral', 'resnet', epochs=10)\n",
    "vgg_model, vgg_history = entrenar_y_mostrar_loss(vgg_model, train_generator, validation_generator, 'oral', 'vgg', epochs=10)\n",
    "densenet_model, densenet_history = entrenar_y_mostrar_loss(densenet_model, train_generator, validation_generator, 'oral', 'densenet', epochs=10)\n",
    "\n",
    "# Usar las mismas imágenes que el modelo personalizado\n",
    "for ruta in rutas_imagenes_prueba:\n",
    "    generar_guardar_mapa_calor(ruta, resnet_model, 'resnet')\n",
    "    generar_guardar_mapa_calor(ruta, vgg_model, 'vgg')\n",
    "    generar_guardar_mapa_calor(ruta, densenet_model, 'densenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
